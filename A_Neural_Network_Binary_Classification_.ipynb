{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqaGHZSJoXCU"
      },
      "outputs": [],
      "source": [
        "# Package imports\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import sklearn.linear_model\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_T80WjXJoZk"
      },
      "outputs": [],
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size =0.2, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHRZYDRQJoZl"
      },
      "outputs": [],
      "source": [
        "scaler = preprocessing.StandardScaler().fit(train_data)\n",
        "train_data = scaler.transform(train_data)\n",
        "test_data = scaler.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDFx7_7TJoZl"
      },
      "outputs": [],
      "source": [
        "trainx = train_data.T\n",
        "trainy = train_labels.reshape(-1,1).T\n",
        "\n",
        "testx = test_data.T\n",
        "testy =test_labels.reshape(-1,1).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKflZhRFJoZm",
        "outputId": "8bb7578c-018a-4394-c7bb-6df17acc740d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((30, 455), (1, 455), (30, 114), (1, 114))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainx.shape, trainy.shape, testx.shape, testy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_L3gSMjJoZm"
      },
      "outputs": [],
      "source": [
        "X=trainx\n",
        "Y=trainy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOsdX_bPoXCx"
      },
      "outputs": [],
      "source": [
        "def model_architecture(X, Y):\n",
        "    \n",
        "    n_x = X.shape[0] \n",
        "    n_h = 10\n",
        "    n_y = Y.shape[0]  \n",
        "   \n",
        "    return (n_x, n_h, n_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV3W6uLvoXC3"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \n",
        "    np.random.seed(2)\n",
        "\n",
        "    \n",
        "    \n",
        "    W1 = np.random.randn(n_h,n_x) * (0.01)\n",
        "    b1 = np.zeros((n_h,1))\n",
        "    W2 = np.random.randn(n_y,n_h) * (0.01)\n",
        "    b2 = np.zeros((n_y,1))\n",
        "   \n",
        "    \n",
        "    assert (W1.shape == (n_h, n_x))\n",
        "    assert (b1.shape == (n_h, 1))\n",
        "    assert (W2.shape == (n_y, n_h))\n",
        "    assert (b2.shape == (n_y, 1))\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcNY-D7rJoZr"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "   \n",
        "    sigmoid = 1/(1 + np.exp(-x))\n",
        "    return sigmoid  \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkJ4TKKSoXC9"
      },
      "outputs": [],
      "source": [
        "def forward_propagation(X, parameters):\n",
        "   \n",
        "   \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    \n",
        "    Z1 =  np.dot(W1,X) + b1  \n",
        "    A1 =  sigmoid(Z1)\n",
        "    Z2 =  np.dot(W2,A1) + b2  \n",
        "    A2 =  sigmoid(Z2) \n",
        " \n",
        "    \n",
        "    assert(A2.shape == (1, X.shape[1]))\n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2}\n",
        "    \n",
        "    return A2, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whxXuxq-oXDD"
      },
      "outputs": [],
      "source": [
        "def compute_cost(A2, Y,parameters):\n",
        "   \n",
        "    \n",
        "    n = Y.shape[1] \n",
        "\n",
        "   \n",
        "    logprobs = np.multiply(np.log(A2),Y)\n",
        "    cost = - np.sum(logprobs)\n",
        "  \n",
        "    \n",
        "    cost = float(np.squeeze(cost))\n",
        "\n",
        "    assert(isinstance(cost, float))\n",
        "    \n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHTVtf4_oXDJ"
      },
      "outputs": [],
      "source": [
        "def backprop(parameters, cache, X, Y):\n",
        "   \n",
        "    n = X.shape[1]\n",
        "    \n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "   \n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    \n",
        "    dZ2 = A2 - Y \n",
        "    dW2 = (dZ2.dot(A1.T)) / n\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims = True) / n\n",
        "    dZ1 = (W2.T.dot(dZ2)) *  (1 - np.power(A1,2))\n",
        "    dW1 = (dZ1.dot(X.T)) / n\n",
        "    db1 = np.sum(dZ1, axis=1, keepdims = True) / n\n",
        "     \n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWeErPRmoXDP"
      },
      "outputs": [],
      "source": [
        "def update(parameters, grads, alpha = 0.01):\n",
        "   \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "   \n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    \n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        " \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnSyk2auoXDU"
      },
      "outputs": [],
      "source": [
        "def NeuralNetwork(X, Y, n_h, num_iterations = 10000, alpha = 0.01, print_cost=False):\n",
        "   \n",
        "    \n",
        "    np.random.seed(3)\n",
        "    n_x = model_architecture(X, Y)[0]\n",
        "    n_y = model_architecture(X, Y)[2]\n",
        "    \n",
        "   \n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    W1 =  parameters['W1']                 \n",
        "    b1 =  parameters['b1']                 \n",
        "    W2 =  parameters['W2']              \n",
        "    b2 =  parameters['b2']\n",
        "    \n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "         \n",
        "      \n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "      \n",
        "        cost = compute_cost(A2, Y, parameters)\n",
        " \n",
        "       \n",
        "        grads = backprop(parameters, cache, X, Y)\n",
        " \n",
        "      \n",
        "        parameters =  update(parameters, grads)\n",
        "        \n",
        "       \n",
        "        if print_cost and i % 100 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPMG_zMloXDZ"
      },
      "outputs": [],
      "source": [
        "def predict(parameters, X):\n",
        "  \n",
        "    \n",
        "  \n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    predictions = A2 > 0.5\n",
        "  \n",
        "    \n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5NM0gXoXDi",
        "outputId": "a97cc60d-020e-4c9f-fe78-bae47886c0f3",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 201.258678\n",
            "Cost after iteration 100: 154.457066\n",
            "Cost after iteration 200: 126.923973\n",
            "Cost after iteration 300: 101.919033\n",
            "Cost after iteration 400: 78.978472\n",
            "Cost after iteration 500: 61.120433\n",
            "Cost after iteration 600: 48.849262\n",
            "Cost after iteration 700: 40.815581\n",
            "Cost after iteration 800: 35.568344\n",
            "Cost after iteration 900: 32.082797\n",
            "Cost after iteration 1000: 29.713367\n",
            "Cost after iteration 1100: 28.062338\n",
            "Cost after iteration 1200: 26.882419\n",
            "Cost after iteration 1300: 26.016989\n",
            "Cost after iteration 1400: 25.364753\n",
            "Cost after iteration 1500: 24.858569\n",
            "Cost after iteration 1600: 24.452435\n",
            "Cost after iteration 1700: 24.113468\n",
            "Cost after iteration 1800: 23.817086\n",
            "Cost after iteration 1900: 23.544299\n",
            "Cost after iteration 2000: 23.280371\n",
            "Cost after iteration 2100: 23.014478\n",
            "Cost after iteration 2200: 22.740163\n",
            "Cost after iteration 2300: 22.456388\n",
            "Cost after iteration 2400: 22.168426\n",
            "Cost after iteration 2500: 21.887283\n",
            "Cost after iteration 2600: 21.626581\n",
            "Cost after iteration 2700: 21.397861\n",
            "Cost after iteration 2800: 21.207123\n",
            "Cost after iteration 2900: 21.054465\n",
            "Cost after iteration 3000: 20.936028\n",
            "Cost after iteration 3100: 20.846311\n",
            "Cost after iteration 3200: 20.779747\n",
            "Cost after iteration 3300: 20.731443\n",
            "Cost after iteration 3400: 20.697384\n",
            "Cost after iteration 3500: 20.674392\n",
            "Cost after iteration 3600: 20.659984\n",
            "Cost after iteration 3700: 20.652236\n",
            "Cost after iteration 3800: 20.649647\n",
            "Cost after iteration 3900: 20.651047\n",
            "Cost after iteration 4000: 20.655514\n",
            "Cost after iteration 4100: 20.662317\n",
            "Cost after iteration 4200: 20.670875\n",
            "Cost after iteration 4300: 20.680718\n",
            "Cost after iteration 4400: 20.691473\n",
            "Cost after iteration 4500: 20.702836\n",
            "Cost after iteration 4600: 20.714564\n",
            "Cost after iteration 4700: 20.726467\n",
            "Cost after iteration 4800: 20.738394\n",
            "Cost after iteration 4900: 20.750231\n",
            "Cost after iteration 5000: 20.761891\n",
            "Cost after iteration 5100: 20.773317\n",
            "Cost after iteration 5200: 20.784470\n",
            "Cost after iteration 5300: 20.795330\n",
            "Cost after iteration 5400: 20.805889\n",
            "Cost after iteration 5500: 20.816153\n",
            "Cost after iteration 5600: 20.826134\n",
            "Cost after iteration 5700: 20.835848\n",
            "Cost after iteration 5800: 20.845318\n",
            "Cost after iteration 5900: 20.854566\n",
            "Cost after iteration 6000: 20.863615\n",
            "Cost after iteration 6100: 20.872486\n",
            "Cost after iteration 6200: 20.881199\n",
            "Cost after iteration 6300: 20.889771\n",
            "Cost after iteration 6400: 20.898217\n",
            "Cost after iteration 6500: 20.906549\n",
            "Cost after iteration 6600: 20.914774\n",
            "Cost after iteration 6700: 20.922901\n",
            "Cost after iteration 6800: 20.930934\n",
            "Cost after iteration 6900: 20.938874\n",
            "Cost after iteration 7000: 20.946723\n",
            "Cost after iteration 7100: 20.954480\n",
            "Cost after iteration 7200: 20.962144\n",
            "Cost after iteration 7300: 20.969711\n",
            "Cost after iteration 7400: 20.977180\n",
            "Cost after iteration 7500: 20.984546\n",
            "Cost after iteration 7600: 20.991808\n",
            "Cost after iteration 7700: 20.998962\n",
            "Cost after iteration 7800: 21.006006\n",
            "Cost after iteration 7900: 21.012936\n",
            "Cost after iteration 8000: 21.019752\n",
            "Cost after iteration 8100: 21.026452\n",
            "Cost after iteration 8200: 21.033035\n",
            "Cost after iteration 8300: 21.039502\n",
            "Cost after iteration 8400: 21.045852\n",
            "Cost after iteration 8500: 21.052086\n",
            "Cost after iteration 8600: 21.058208\n",
            "Cost after iteration 8700: 21.064218\n",
            "Cost after iteration 8800: 21.070120\n",
            "Cost after iteration 8900: 21.075916\n",
            "Cost after iteration 9000: 21.081612\n",
            "Cost after iteration 9100: 21.087212\n",
            "Cost after iteration 9200: 21.092720\n",
            "Cost after iteration 9300: 21.098141\n",
            "Cost after iteration 9400: 21.103481\n",
            "Cost after iteration 9500: 21.108745\n",
            "Cost after iteration 9600: 21.113941\n",
            "Cost after iteration 9700: 21.119074\n",
            "Cost after iteration 9800: 21.124150\n",
            "Cost after iteration 9900: 21.129177\n"
          ]
        }
      ],
      "source": [
        "# Build a model with a n_h-dimensional hidden layer\n",
        "parameters = NeuralNetwork(X, Y, n_h = 10, num_iterations = 10000, print_cost=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUdvhN9BoXDn",
        "outputId": "72156ff2-c3e4-4b99-b0a7-ca8fc405e6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9736263736263736\n"
          ]
        }
      ],
      "source": [
        "# Print accuracy\n",
        "predictions = predict(parameters, X)\n",
        "print(accuracy_score(Y.T, predictions.T))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "wRuwL",
      "launcher_item_id": "NI888"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}