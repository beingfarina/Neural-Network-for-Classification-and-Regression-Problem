{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqaGHZSJoXCU"
      },
      "outputs": [],
      "source": [
        "# Package imports\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfCyaMR7WSS1"
      },
      "outputs": [],
      "source": [
        "#importing the data\n",
        "\n",
        "import pandas as pd\n",
        "data = pd.read_csv(r'C:\\Users\\Farina Tariq\\Downloads\\data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n3PBHecmWkH5",
        "outputId": "597666de-26be-4a92-fd55-656b3f41bb0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missouri</th>\n",
              "      <th>Mississippi</th>\n",
              "      <th>Yukon</th>\n",
              "      <th>Rio Grande</th>\n",
              "      <th>Target Variable Rio Grande</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.66</td>\n",
              "      <td>15.65</td>\n",
              "      <td>120.173</td>\n",
              "      <td>155.552</td>\n",
              "      <td>102.518</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.84</td>\n",
              "      <td>42.91</td>\n",
              "      <td>25.042</td>\n",
              "      <td>61.937</td>\n",
              "      <td>155.552</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.20</td>\n",
              "      <td>54.76</td>\n",
              "      <td>47.627</td>\n",
              "      <td>159.542</td>\n",
              "      <td>61.937</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.43</td>\n",
              "      <td>58.47</td>\n",
              "      <td>86.291</td>\n",
              "      <td>122.878</td>\n",
              "      <td>159.542</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.42</td>\n",
              "      <td>31.76</td>\n",
              "      <td>58.055</td>\n",
              "      <td>12.152</td>\n",
              "      <td>122.878</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Missouri  Mississippi   Yukon   Rio Grande  Target Variable Rio Grande  \\\n",
              "0     28.66        15.65  120.173     155.552                     102.518   \n",
              "1     24.84        42.91   25.042      61.937                     155.552   \n",
              "2     29.20        54.76   47.627     159.542                      61.937   \n",
              "3      3.43        58.47   86.291     122.878                     159.542   \n",
              "4     51.42        31.76   58.055      12.152                     122.878   \n",
              "\n",
              "  Unnamed: 5  \n",
              "0             \n",
              "1        NaN  \n",
              "2        NaN  \n",
              "3        NaN  \n",
              "4        NaN  "
            ]
          },
          "execution_count": 231,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#data description\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpMYN93eCKW3",
        "outputId": "6e08b664-12f9-4d03-b941-018ca0dff0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1461 entries, 0 to 1460\n",
            "Data columns (total 6 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   Missouri                    1460 non-null   float64\n",
            " 1   Mississippi                 1460 non-null   float64\n",
            " 2   Yukon                       1460 non-null   float64\n",
            " 3   Rio Grande                  1460 non-null   float64\n",
            " 4   Target Variable Rio Grande  1460 non-null   float64\n",
            " 5   Unnamed: 5                  1 non-null      object \n",
            "dtypes: float64(5), object(1)\n",
            "memory usage: 62.8+ KB\n"
          ]
        }
      ],
      "source": [
        "#data information\n",
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzLCdFwlCKW4"
      },
      "outputs": [],
      "source": [
        "#dropping null column\n",
        "\n",
        "df = data.drop(['Unnamed: 5'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGYKrnRNCKW4",
        "outputId": "4935d53b-1a16-4662-c2ac-198ecbf483b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missouri</th>\n",
              "      <th>Mississippi</th>\n",
              "      <th>Yukon</th>\n",
              "      <th>Rio Grande</th>\n",
              "      <th>Target Variable Rio Grande</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28.66</td>\n",
              "      <td>15.65</td>\n",
              "      <td>120.173</td>\n",
              "      <td>155.552</td>\n",
              "      <td>102.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>24.84</td>\n",
              "      <td>42.91</td>\n",
              "      <td>25.042</td>\n",
              "      <td>61.937</td>\n",
              "      <td>155.552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29.20</td>\n",
              "      <td>54.76</td>\n",
              "      <td>47.627</td>\n",
              "      <td>159.542</td>\n",
              "      <td>61.937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.43</td>\n",
              "      <td>58.47</td>\n",
              "      <td>86.291</td>\n",
              "      <td>122.878</td>\n",
              "      <td>159.542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.42</td>\n",
              "      <td>31.76</td>\n",
              "      <td>58.055</td>\n",
              "      <td>12.152</td>\n",
              "      <td>122.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>44.66</td>\n",
              "      <td>8.17</td>\n",
              "      <td>125.089</td>\n",
              "      <td>96.610</td>\n",
              "      <td>129.715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>59.71</td>\n",
              "      <td>35.29</td>\n",
              "      <td>116.039</td>\n",
              "      <td>125.576</td>\n",
              "      <td>96.610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>56.09</td>\n",
              "      <td>51.77</td>\n",
              "      <td>48.138</td>\n",
              "      <td>21.064</td>\n",
              "      <td>125.576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>28.92</td>\n",
              "      <td>31.12</td>\n",
              "      <td>9.518</td>\n",
              "      <td>167.055</td>\n",
              "      <td>21.064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>20.58</td>\n",
              "      <td>47.29</td>\n",
              "      <td>129.703</td>\n",
              "      <td>121.972</td>\n",
              "      <td>167.055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1460 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Missouri  Mississippi   Yukon   Rio Grande  Target Variable Rio Grande\n",
              "0        28.66        15.65  120.173     155.552                     102.518\n",
              "1        24.84        42.91   25.042      61.937                     155.552\n",
              "2        29.20        54.76   47.627     159.542                      61.937\n",
              "3         3.43        58.47   86.291     122.878                     159.542\n",
              "4        51.42        31.76   58.055      12.152                     122.878\n",
              "...        ...          ...      ...         ...                         ...\n",
              "1455     44.66         8.17  125.089      96.610                     129.715\n",
              "1456     59.71        35.29  116.039     125.576                      96.610\n",
              "1457     56.09        51.77   48.138      21.064                     125.576\n",
              "1458     28.92        31.12    9.518     167.055                      21.064\n",
              "1459     20.58        47.29  129.703     121.972                     167.055\n",
              "\n",
              "[1460 rows x 5 columns]"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dropping null values\n",
        "\n",
        "df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fZlRq1ACKW4"
      },
      "outputs": [],
      "source": [
        "df = df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy9d4NDbLGuK"
      },
      "outputs": [],
      "source": [
        "#splitting of data into features and target variable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "X = df[:,0:4]\n",
        "y = df[:,4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8j3m5ZgCKW5"
      },
      "outputs": [],
      "source": [
        "#data type conversion\n",
        "\n",
        "X = X.astype(np.int64)\n",
        "y = y.astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_T80WjXJoZk"
      },
      "outputs": [],
      "source": [
        "#splitting into training, testing and validation data\n",
        "\n",
        "x_data, test_data, y_data, test_labels = train_test_split(X, y, test_size =0.2, random_state=0)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(x_data, y_data, test_size =0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHRZYDRQJoZl"
      },
      "outputs": [],
      "source": [
        "#scaling of data\n",
        "\n",
        "scaler = preprocessing.StandardScaler().fit(train_data)\n",
        "train_data = scaler.transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "val_data = scaler.transform(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDFx7_7TJoZl"
      },
      "outputs": [],
      "source": [
        "trainx = train_data.T\n",
        "trainy = train_labels.reshape(-1,1).T\n",
        "\n",
        "testx = test_data.T\n",
        "testy =test_labels.reshape(-1,1).T\n",
        "\n",
        "valx = val_data.T\n",
        "valy = val_labels.reshape(-1,1).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKflZhRFJoZm",
        "outputId": "4f314a25-8723-4c8a-ebac-7d4ba1b78f65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4, 876), (1, 876), (4, 293), (1, 293), (4, 292), (1, 292))"
            ]
          },
          "execution_count": 241,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainx.shape, trainy.shape, testx.shape, testy.shape, valx.shape, valy.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_L3gSMjJoZm"
      },
      "outputs": [],
      "source": [
        "X=trainx\n",
        "Y=trainy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFAQt6HYoXCh",
        "outputId": "2b323007-a776-4370-f80e-9f86c5aead38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of training samples: 876\n",
            "Number of features per sample: 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "shape_X = X.shape\n",
        "shape_Y = Y.shape\n",
        "n = X.shape[1]                  \n",
        "\n",
        "\n",
        "print ('No. of training samples: ' + str(n))\n",
        "print ('Number of features per sample: ' + str(shape_X[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOsdX_bPoXCx"
      },
      "outputs": [],
      "source": [
        "#defining model structure\n",
        "\n",
        "def model_architecture(X, Y):\n",
        "   \n",
        "    n_x = X.shape[0]                       # n_x -- the size of the input layer\n",
        "    n_h = 5                                # n_h -- the size of the hidden layer\n",
        "    n_y = 1                                # n_y -- the size of the output layer\n",
        "  \n",
        "    return (n_x, n_h, n_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XV3W6uLvoXC3"
      },
      "outputs": [],
      "source": [
        "#defining the weight initializing function\n",
        "\n",
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \n",
        "    np.random.seed(1)\n",
        "\n",
        "    W1 = np.random.randn(n_h,n_x) * (0.01)                 # W1 -- weight matrix of shape (n_h, n_x)\n",
        "    b1 =  np.zeros((n_h,1))                                # b1 -- bias vector of shape (n_h, 1)\n",
        "    W2 = np.random.randn(n_y,n_h) * (0.01)                  # W2 -- weight matrix of shape (n_y, n_h)\n",
        "    b2 = np.zeros((n_y,1))                                 # b2 -- bias vector of shape (n_y, 1)\n",
        "    \n",
        "    assert (W1.shape == (n_h, n_x))\n",
        "    assert (b1.shape == (n_h, 1))\n",
        "    assert (W2.shape == (n_y, n_h))\n",
        "    assert (b2.shape == (n_y, 1))\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXiD6jishUhn"
      },
      "outputs": [],
      "source": [
        "#sigmoid activation function\n",
        "\n",
        "def sigmoid(x):\n",
        "  \n",
        "    sigmoid = 1/(1 + np.exp(-x))\n",
        "    return sigmoid  \n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMuF7-8kD1Ig"
      },
      "outputs": [],
      "source": [
        "#tanh activation function\n",
        "\n",
        "def tanh(x):\n",
        "   \n",
        "    return 2 * sigmoid(2*x)-1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkJ4TKKSoXC9"
      },
      "outputs": [],
      "source": [
        "#feed forward function\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "\n",
        "    # Implement Forward Propagation to calculate A2 (probabilities)\n",
        "\n",
        "    Z1 = np.dot(W1,X) + b1                        \n",
        "    A1 = sigmoid(Z1)                          \n",
        "    Z2 = np.dot(W2,A1) + b2                      \n",
        "    A2 = sigmoid(Z2)                         \n",
        "\n",
        "    assert(A2.shape == (1, X.shape[1]))\n",
        "    \n",
        "    cache = {\"Z1\": Z1,\n",
        "             \"A1\": A1,\n",
        "             \"Z2\": Z2,\n",
        "             \"A2\": A2}\n",
        "    \n",
        "    return A2, cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whxXuxq-oXDD"
      },
      "outputs": [],
      "source": [
        "#cost function (Mmean Square Error MSE)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "\n",
        "def compute_cost(A2, Y,parameters):\n",
        "  n = Y.shape[1] # number of example\n",
        "  \n",
        "  MSE = mean_squared_error(Y, A2)\n",
        " \n",
        "  cost = math.sqrt(MSE)\n",
        "  cost = float(np.squeeze(cost))\n",
        "  assert(isinstance(cost, float))\n",
        "  return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHTVtf4_oXDJ"
      },
      "outputs": [],
      "source": [
        "#backpropagation function\n",
        "\n",
        "def backprop(parameters, cache, X, Y):\n",
        "    \n",
        "    n = X.shape[1]\n",
        "    \n",
        "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
        "    \n",
        "    W1 = parameters['W1']\n",
        "    W2 = parameters['W2']\n",
        "    \n",
        "        \n",
        "    # Retrieve also A1 and A2 from dictionary \"cache\".\n",
        "     \n",
        "    A1 = cache['A1']\n",
        "    A2 = cache['A2']\n",
        "    \n",
        "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
        "   \n",
        "    dZ2 = A2 - Y      \n",
        "    dW2 = (dZ2.dot(A1.T)) / n\n",
        "    db2 = np.sum(dZ2, axis=1, keepdims = True) / n\n",
        "    dZ1 = (W2.T.dot(dZ2)) *  (1 - np.power(A1,2))\n",
        "    dW1 = (dZ1.dot(X.T)) / n \n",
        "    db1 = np.sum(dZ1, axis=1, keepdims = True) / n\n",
        "    \n",
        "    grads = {\"dW1\": dW1,\n",
        "             \"db1\": db1,\n",
        "             \"dW2\": dW2,\n",
        "             \"db2\": db2}\n",
        "    \n",
        "    return grads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWeErPRmoXDP"
      },
      "outputs": [],
      "source": [
        "#weight decay function\n",
        "\n",
        "def update(parameters, grads, alpha = 0.001):\n",
        "    \n",
        "    # Retrieve each parameter from the dictionary \"parameters\"\n",
        "  \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    \n",
        "    # Retrieve each gradient from the dictionary \"grads\"\n",
        "    \n",
        "    dW1 = grads['dW1']\n",
        "    db1 = grads['db1']\n",
        "    dW2 = grads['dW2']\n",
        "    db2 = grads['db2']\n",
        "    \n",
        "    # Update rule for each parameter\n",
        "  \n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2- alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2}\n",
        "    \n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnSyk2auoXDU"
      },
      "outputs": [],
      "source": [
        "#neural network model \n",
        "\n",
        "def NeuralNetwork(X, Y, n_h, num_epochs = 10, alpha = 0.001, print_cost=False):\n",
        "   \n",
        "    np.random.seed(1)\n",
        "    n_x = model_architecture(X, Y)[0]\n",
        "    n_y = model_architecture(X, Y)[2]\n",
        "    \n",
        "    # Initialize parameters\n",
        "    \n",
        "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
        "    W1 =  parameters['W1']                 # W1 -- weight matrix of shape (n_h, n_x)\n",
        "    b1 =  parameters['b1']                 # b1 -- bias vector of shape (n_h, 1)\n",
        "    W2 =  parameters['W2']                 # W2 -- weight matrix of shape (n_y, n_h)\n",
        "    b2 =  parameters['b2']                 # b2 -- bias vector of shape (n_y, 1)\n",
        "  \n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_epochs):\n",
        "\n",
        "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
        "        A2, cache = forward_propagation(X, parameters)\n",
        "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
        "        cost = compute_cost(A2, Y, parameters)\n",
        "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
        "        grads = backprop(parameters, cache, X, Y)\n",
        "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
        "        parameters = update(parameters, grads)\n",
        "\n",
        "        # Print the cost every 1 epochs\n",
        "        if print_cost and i % 1 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op5NM0gXoXDi",
        "outputId": "12e5b513-096d-42d2-c5b8-7fb2096c5248",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after iteration 0: 311628862009368640.000000\n",
            "Cost after iteration 1: 311628862009368640.000000\n",
            "Cost after iteration 2: 311628862009368640.000000\n",
            "Cost after iteration 3: 311628862009368640.000000\n",
            "Cost after iteration 4: 311628862009368640.000000\n",
            "Cost after iteration 5: 311628862009368640.000000\n",
            "Cost after iteration 6: 311628862009368640.000000\n",
            "Cost after iteration 7: 311628862009368640.000000\n",
            "Cost after iteration 8: 311628862009368640.000000\n",
            "Cost after iteration 9: 311628862009368640.000000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n",
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "# Build a model with a n_h-dimensional hidden layer\n",
        "\n",
        "parameters = NeuralNetwork(X, Y, n_h = 5 , num_epochs = 10, print_cost=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tezST7WFioUA"
      },
      "outputs": [],
      "source": [
        "#prediction function\n",
        "\n",
        "def predict(parameters, X):\n",
        "    \n",
        "    A2, cache = forward_propagation(X, parameters)\n",
        "    predictions = A2 \n",
        "    \n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUdvhN9BoXDn",
        "outputId": "83a881cc-50a9-4f15-f61d-9b46cd3b9ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.1162886200936864e+17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "# Print MSE for training data\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "predictions = predict(parameters, trainx)\n",
        "print(mean_squared_error(predictions, trainy, squared=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GVN67FwJoZ5",
        "outputId": "478b2bed-a558-4f5b-e01d-09b43bf12842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120.59198406677125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "#MSE for testing data\n",
        "\n",
        "predictions_test = predict(parameters, testx)\n",
        "print(mean_squared_error(predictions_test,testy,squared=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeBTjBB1j-rw",
        "outputId": "6d304113-4cde-444c-cba1-2dd3c1207dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125.63180057242073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-246-db37c8f5e929>:5: RuntimeWarning: overflow encountered in exp\n",
            "  sigmoid = 1/(1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "#MSE for validation data\n",
        "\n",
        "predictions_val = predict(parameters, valx)\n",
        "print(mean_squared_error(valy, predictions_val,squared=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M_B02pNDxxK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMEYzrrACKW_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "wRuwL",
      "launcher_item_id": "NI888"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}